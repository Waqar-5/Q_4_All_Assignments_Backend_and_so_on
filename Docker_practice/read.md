# ğŸ¤– Backend Agentic AI API

A **production-ready Agentic AI backend** built with **FastAPI**, containerized using **Docker**, and deployed on **Hugging Face Spaces**. This project demonstrates how to expose an AI agent as a clean REST API and connect it with modern LLM providers like **OpenRouter (free models)**.

---

## ğŸš€ Live Overview

* **Framework**: FastAPI
* **Deployment**: Hugging Face Spaces (Docker)
* **AI Provider**: OpenRouter (Free Models)
* **Server**: Uvicorn
* **Architecture**: Agent-based backend

This backend is designed to be:

* âœ… Simple
* âœ… Scalable
* âœ… Frontend-ready
* âœ… Cloud deployable

---

## ğŸ“‚ Project Structure

```
backend-agent/
â”‚
â”œâ”€â”€ main.py              # FastAPI entry point
â”œâ”€â”€ agent_main.py        # Core agent logic
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile           # Docker build instructions
â”œâ”€â”€ .env                 # Environment variables (API keys)
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸ§  How the Agent Works

1. Client sends a message to `/chat`
2. FastAPI receives the request
3. Message is passed to `run_agent()`
4. Agent communicates with OpenRouter LLM
5. Response is returned as JSON

---

## ğŸ§© API Endpoints

### ğŸ”¹ Health Check

```http
GET /
```

**Response**

```json
{
  "status": "Agent API is running ğŸš€"
}
```

---

### ğŸ”¹ Chat with Agent

```http
POST /chat
```

**Request Body**

```json
{
  "message": "Hello Agent"
}
```

**Response**

```json
{
  "reply": "Hello! How can I help you today?"
}
```

---

## ğŸ§ª Swagger UI (Built-in)

FastAPI automatically provides interactive docs:

```
/docs
```

You can test all endpoints directly from the browser.

---

## ğŸ³ Docker Setup

### Dockerfile (Key Idea)

* Uses lightweight Python base image
* Installs dependencies via `requirements.txt`
* Runs FastAPI using Uvicorn

### Build Locally

```bash
docker build -t backend-agent .
```

### Run Locally

```bash
docker run -p 8000:8000 backend-agent
```

---

## â˜ï¸ Deployment on Hugging Face Spaces

1. Create a **Docker Space**
2. Push this repository to Hugging Face
3. Add secrets in **Space Settings**:

```env
OPENROUTER_API_KEY=your_api_key_here
```

4. Space auto-builds and deploys ğŸš€

---

## ğŸ” Environment Variables

Create a `.env` file locally:

```env
OPENROUTER_API_KEY=your_api_key_here
```

Never commit API keys to GitHub.

---

## ğŸ§  Why This Project Is Powerful

* ğŸ§© Agent-based architecture
* ğŸŒ Clean REST API
* ğŸ³ Dockerized deployment
* ğŸ¤— Hugging Face compatible
* ğŸ” Easy model switching (OpenRouter)
* âš¡ Fast & lightweight

---

## ğŸ›  Tech Stack

* **Python 3.11**
* **FastAPI**
* **Uvicorn**
* **Docker**
* **OpenRouter API**
* **Hugging Face Spaces**

---

## ğŸ“ˆ Future Enhancements

* âœ… Streaming responses
* âœ… Conversation memory
* âœ… Authentication
* âœ… Frontend (React / Next.js)
* âœ… Multi-agent orchestration

---

## ğŸ‘¤ Author

**Waqar Ali**
Agentic AI Developer | FastAPI | Docker | Hugging Face

---

## â­ Support

If you like this project:

* â­ Star the Space
* ğŸ¤ Share with others
* ğŸ§  Build your own agent on top of it

---

### ğŸš€ Ready to build the future with Agentic AI

Happy coding! ğŸ¤–âœ¨
